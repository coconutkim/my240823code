{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "# sequential 순차적으로 레이어를 쌓아올리는 방식으로 모델을 구성한다\n",
    "# 각 레이어는 이전의 출력을 입력으로 받아 다음 레이어로 전달한다\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'DOSKEY'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
      "��ġ ������ �ƴմϴ�.\n",
      "fatal: destination path 'data' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/taehojo/data.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>plasma</th>\n",
       "      <th>pressure</th>\n",
       "      <th>thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pregnant  plasma  pressure  thickness  insulin   bmi  pedigree  age  \\\n",
       "0           6     148        72         35        0  33.6     0.627   50   \n",
       "1           1      85        66         29        0  26.6     0.351   31   \n",
       "2           8     183        64          0        0  23.3     0.672   32   \n",
       "3           1      89        66         23       94  28.1     0.167   21   \n",
       "4           0     137        40         35      168  43.1     2.288   33   \n",
       "..        ...     ...       ...        ...      ...   ...       ...  ...   \n",
       "763        10     101        76         48      180  32.9     0.171   63   \n",
       "764         2     122        70         27        0  36.8     0.340   27   \n",
       "765         5     121        72         23      112  26.2     0.245   30   \n",
       "766         1     126        60          0        0  30.1     0.349   47   \n",
       "767         1      93        70         31        0  30.4     0.315   23   \n",
       "\n",
       "     diabetes  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           0  \n",
       "4           1  \n",
       "..        ...  \n",
       "763         0  \n",
       "764         0  \n",
       "765         0  \n",
       "766         1  \n",
       "767         0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima_set=pd.read_csv('C:/ex/taehojo_data/pima-indians-diabetes3 - 복사본.csv')\n",
    "pima_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   pregnant   768 non-null    int64  \n",
      " 1   plasma     768 non-null    int64  \n",
      " 2   pressure   768 non-null    int64  \n",
      " 3   thickness  768 non-null    int64  \n",
      " 4   insulin    768 non-null    int64  \n",
      " 5   bmi        768 non-null    float64\n",
      " 6   pedigree   768 non-null    float64\n",
      " 7   age        768 non-null    int64  \n",
      " 8   diabetes   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "pima_set.info()\n",
    "# non null 결측치가 없다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>plasma</th>\n",
       "      <th>pressure</th>\n",
       "      <th>thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnant  plasma  pressure  thickness  insulin   bmi  pedigree  age  \\\n",
       "0         6     148        72         35        0  33.6     0.627   50   \n",
       "1         1      85        66         29        0  26.6     0.351   31   \n",
       "2         8     183        64          0        0  23.3     0.672   32   \n",
       "3         1      89        66         23       94  28.1     0.167   21   \n",
       "4         0     137        40         35      168  43.1     2.288   33   \n",
       "\n",
       "   diabetes  \n",
       "0         1  \n",
       "1         0  \n",
       "2         1  \n",
       "3         0  \n",
       "4         1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima_set.head() #기본값은 5\n",
    "# 가장 윗단의 5개의 데이터를 보겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diabetes\n",
       "0    500\n",
       "1    268\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima_set['diabetes'].value_counts()\n",
    "# 정상인 500명과 당뇨병 환자 268명\n",
    "# 총 768개의 샘플"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima_set.diabetes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>plasma</th>\n",
       "      <th>pressure</th>\n",
       "      <th>thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pregnant      plasma    pressure   thickness     insulin         bmi  \\\n",
       "count  768.000000  768.000000  768.000000  768.000000  768.000000  768.000000   \n",
       "mean     3.845052  120.894531   69.105469   20.536458   79.799479   31.992578   \n",
       "std      3.369578   31.972618   19.355807   15.952218  115.244002    7.884160   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.000000   99.000000   62.000000    0.000000    0.000000   27.300000   \n",
       "50%      3.000000  117.000000   72.000000   23.000000   30.500000   32.000000   \n",
       "75%      6.000000  140.250000   80.000000   32.000000  127.250000   36.600000   \n",
       "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
       "\n",
       "         pedigree         age    diabetes  \n",
       "count  768.000000  768.000000  768.000000  \n",
       "mean     0.471876   33.240885    0.348958  \n",
       "std      0.331329   11.760232    0.476951  \n",
       "min      0.078000   21.000000    0.000000  \n",
       "25%      0.243750   24.000000    0.000000  \n",
       "50%      0.372500   29.000000    0.000000  \n",
       "75%      0.626250   41.000000    1.000000  \n",
       "max      2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima_set.describe()\n",
    "# 샘플 수, 평균, 표준편차, 최솟값, 백분위 수로 해당하는 값, 최댓값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>plasma</th>\n",
       "      <th>pressure</th>\n",
       "      <th>thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pregnant</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.129459</td>\n",
       "      <td>0.141282</td>\n",
       "      <td>-0.081672</td>\n",
       "      <td>-0.073535</td>\n",
       "      <td>0.017683</td>\n",
       "      <td>-0.033523</td>\n",
       "      <td>0.544341</td>\n",
       "      <td>0.221898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plasma</th>\n",
       "      <td>0.129459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.331357</td>\n",
       "      <td>0.221071</td>\n",
       "      <td>0.137337</td>\n",
       "      <td>0.263514</td>\n",
       "      <td>0.466581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pressure</th>\n",
       "      <td>0.141282</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.281805</td>\n",
       "      <td>0.041265</td>\n",
       "      <td>0.239528</td>\n",
       "      <td>0.065068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thickness</th>\n",
       "      <td>-0.081672</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>0.074752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insulin</th>\n",
       "      <td>-0.073535</td>\n",
       "      <td>0.331357</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.197859</td>\n",
       "      <td>0.185071</td>\n",
       "      <td>-0.042163</td>\n",
       "      <td>0.130548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>0.017683</td>\n",
       "      <td>0.221071</td>\n",
       "      <td>0.281805</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.197859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140647</td>\n",
       "      <td>0.036242</td>\n",
       "      <td>0.292695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pedigree</th>\n",
       "      <td>-0.033523</td>\n",
       "      <td>0.137337</td>\n",
       "      <td>0.041265</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>0.185071</td>\n",
       "      <td>0.140647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>0.173844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.544341</td>\n",
       "      <td>0.263514</td>\n",
       "      <td>0.239528</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>-0.042163</td>\n",
       "      <td>0.036242</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.238356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>0.221898</td>\n",
       "      <td>0.466581</td>\n",
       "      <td>0.065068</td>\n",
       "      <td>0.074752</td>\n",
       "      <td>0.130548</td>\n",
       "      <td>0.292695</td>\n",
       "      <td>0.173844</td>\n",
       "      <td>0.238356</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pregnant    plasma  pressure  thickness   insulin       bmi  \\\n",
       "pregnant   1.000000  0.129459  0.141282  -0.081672 -0.073535  0.017683   \n",
       "plasma     0.129459  1.000000  0.152590   0.057328  0.331357  0.221071   \n",
       "pressure   0.141282  0.152590  1.000000   0.207371  0.088933  0.281805   \n",
       "thickness -0.081672  0.057328  0.207371   1.000000  0.436783  0.392573   \n",
       "insulin   -0.073535  0.331357  0.088933   0.436783  1.000000  0.197859   \n",
       "bmi        0.017683  0.221071  0.281805   0.392573  0.197859  1.000000   \n",
       "pedigree  -0.033523  0.137337  0.041265   0.183928  0.185071  0.140647   \n",
       "age        0.544341  0.263514  0.239528  -0.113970 -0.042163  0.036242   \n",
       "diabetes   0.221898  0.466581  0.065068   0.074752  0.130548  0.292695   \n",
       "\n",
       "           pedigree       age  diabetes  \n",
       "pregnant  -0.033523  0.544341  0.221898  \n",
       "plasma     0.137337  0.263514  0.466581  \n",
       "pressure   0.041265  0.239528  0.065068  \n",
       "thickness  0.183928 -0.113970  0.074752  \n",
       "insulin    0.185071 -0.042163  0.130548  \n",
       "bmi        0.140647  0.036242  0.292695  \n",
       "pedigree   1.000000  0.033561  0.173844  \n",
       "age        0.033561  1.000000  0.238356  \n",
       "diabetes   0.173844  0.238356  1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima_set.corr() #각 항목의 상관관계를 알아본다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pima_set.values[:,:8]\n",
    "#전체 행, 첫 8개의 열\n",
    "#일반적으로 모델의 독립 변수 feature\n",
    "\n",
    "y=pima_set.values[:,8]\n",
    "#전체 행, 9번째 열\n",
    "#일반적으로 모델의 종속 변수 target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### x는 대문자로, y는 소문자로 나타내는 이유\n",
    "\n",
    "> 대문자 x\n",
    "\n",
    "관례적으로 그 데이터가 행렬임을 나타냅니다\n",
    "\n",
    "행렬은 여러 개의 샘플과 여러 개의 특징을 포함하는 2차원 배열입니다\n",
    "\n",
    "> 소문자 y\n",
    "\n",
    "이 데이터가 벡터임을 나타냅니다\n",
    "\n",
    "벡터는 단일 종속 변수의 여러 샘플 값을 담고 있는 1차원 배열입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24/24 [==============================] - 1s 2ms/step - loss: 4.0102 - accuracy: 0.5586\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 2.4302 - accuracy: 0.5911\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 2.1639 - accuracy: 0.6068\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 1.9412 - accuracy: 0.6081\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 1.8343 - accuracy: 0.6198\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 0s 985us/step - loss: 1.6918 - accuracy: 0.6081\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 1.4672 - accuracy: 0.5977\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 1.3219 - accuracy: 0.6133\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 0s 999us/step - loss: 1.2225 - accuracy: 0.6263\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 0s 965us/step - loss: 1.1219 - accuracy: 0.6224\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 1.0622 - accuracy: 0.6354\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.9842 - accuracy: 0.6315\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 1.0164 - accuracy: 0.6094\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.9472 - accuracy: 0.6497\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.8635 - accuracy: 0.6367\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.8613 - accuracy: 0.6276\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.8391 - accuracy: 0.6445\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.8346 - accuracy: 0.6341\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.8013 - accuracy: 0.6615\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.7601 - accuracy: 0.6654\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.7474 - accuracy: 0.6602\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.7579 - accuracy: 0.6719\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.7503 - accuracy: 0.6602\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.8015 - accuracy: 0.6432\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.7285 - accuracy: 0.6667\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.7088 - accuracy: 0.6797\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.7468 - accuracy: 0.6680\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.7230 - accuracy: 0.6849\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6714 - accuracy: 0.6953\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 0s 948us/step - loss: 0.6715 - accuracy: 0.6914\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6767 - accuracy: 0.6849\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6677 - accuracy: 0.7109\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.6801 - accuracy: 0.6862\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6649 - accuracy: 0.6797\n",
      "Epoch 35/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6341 - accuracy: 0.7109\n",
      "Epoch 36/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6307 - accuracy: 0.7240\n",
      "Epoch 37/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6306 - accuracy: 0.7227\n",
      "Epoch 38/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6852 - accuracy: 0.6784\n",
      "Epoch 39/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6499 - accuracy: 0.6836\n",
      "Epoch 40/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6760 - accuracy: 0.6745\n",
      "Epoch 41/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6286 - accuracy: 0.7201\n",
      "Epoch 42/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6170 - accuracy: 0.7031\n",
      "Epoch 43/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6278 - accuracy: 0.7096\n",
      "Epoch 44/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6418 - accuracy: 0.6979\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6169 - accuracy: 0.7096\n",
      "Epoch 46/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6187 - accuracy: 0.6979\n",
      "Epoch 47/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6048 - accuracy: 0.7161\n",
      "Epoch 48/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5939 - accuracy: 0.7188\n",
      "Epoch 49/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6035 - accuracy: 0.7148\n",
      "Epoch 50/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6031 - accuracy: 0.7148\n",
      "Epoch 51/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5945 - accuracy: 0.7253\n",
      "Epoch 52/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6806 - accuracy: 0.6510\n",
      "Epoch 53/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6063 - accuracy: 0.7070\n",
      "Epoch 54/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6081 - accuracy: 0.7031\n",
      "Epoch 55/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6203 - accuracy: 0.6953\n",
      "Epoch 56/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6228 - accuracy: 0.6875\n",
      "Epoch 57/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5849 - accuracy: 0.7240\n",
      "Epoch 58/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5586 - accuracy: 0.7383\n",
      "Epoch 59/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5698 - accuracy: 0.7409\n",
      "Epoch 60/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5669 - accuracy: 0.7253\n",
      "Epoch 61/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5573 - accuracy: 0.7357\n",
      "Epoch 62/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.7461\n",
      "Epoch 63/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5733 - accuracy: 0.7292\n",
      "Epoch 64/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5531 - accuracy: 0.7409\n",
      "Epoch 65/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5542 - accuracy: 0.7461\n",
      "Epoch 66/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5551 - accuracy: 0.7383\n",
      "Epoch 67/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7461\n",
      "Epoch 68/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5497 - accuracy: 0.7500\n",
      "Epoch 69/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5537 - accuracy: 0.7370\n",
      "Epoch 70/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.5719 - accuracy: 0.7370\n",
      "Epoch 71/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5586 - accuracy: 0.7331\n",
      "Epoch 72/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.7435\n",
      "Epoch 73/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7435\n",
      "Epoch 74/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7461\n",
      "Epoch 75/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.7552\n",
      "Epoch 76/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.7135\n",
      "Epoch 77/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.7201\n",
      "Epoch 78/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5470 - accuracy: 0.7448\n",
      "Epoch 79/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5296 - accuracy: 0.7539\n",
      "Epoch 80/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.5339 - accuracy: 0.7630\n",
      "Epoch 81/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7526\n",
      "Epoch 82/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5275 - accuracy: 0.7409\n",
      "Epoch 83/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5107 - accuracy: 0.7669\n",
      "Epoch 84/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5416 - accuracy: 0.7500\n",
      "Epoch 85/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5254 - accuracy: 0.7461\n",
      "Epoch 86/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5226 - accuracy: 0.7526\n",
      "Epoch 87/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.5346 - accuracy: 0.7344\n",
      "Epoch 88/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7552\n",
      "Epoch 89/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5138 - accuracy: 0.7513\n",
      "Epoch 90/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5207 - accuracy: 0.7578\n",
      "Epoch 91/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5117 - accuracy: 0.7591\n",
      "Epoch 92/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5371 - accuracy: 0.7266\n",
      "Epoch 93/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5201 - accuracy: 0.7539\n",
      "Epoch 94/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5144 - accuracy: 0.7409\n",
      "Epoch 95/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5001 - accuracy: 0.7487\n",
      "Epoch 96/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7370\n",
      "Epoch 97/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7695\n",
      "Epoch 98/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7357\n",
      "Epoch 99/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7513\n",
      "Epoch 100/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5266 - accuracy: 0.7435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1de8ea4b3d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "# 시퀀셜 클래스를 사용하여 모델을 생성한다\n",
    "\n",
    "model.add(Dense(12,input_dim=8,activation='relu',name='Dense_1'))\n",
    "# 은닉층\n",
    "# 입력 차원이 8, 12개의 뉴런을 가진 밀집 dense 레이어를 추가한다\n",
    "# 활성화 함수는 렐루\n",
    "\n",
    "model.add(Dense(8,activation='relu',name='Dense_2'))\n",
    "# 은닉층\n",
    "# 8개의 뉴런을 가진 또 다른 밀집 레이어를 추가한다\n",
    "\n",
    "model.add(Dense(1,activation='sigmoid',name='Dense_3'))\n",
    "# 출력층\n",
    "# 1개의 뉴런과 시그모이드 활성화 함수를 사용한다\n",
    "# 분류 문제에서 최종 출력 레이어다\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',metrics=['accuracy'])\n",
    "# 이진 분류를 위해서 손실 함수로 바이너리 크로스엔트로피를 사용한다\n",
    "# 아담 옵티마이저를 사용해서 학습을 최적화한다\n",
    "# 모델의 성능을 평가할 때 정확도를 기준으로 한다\n",
    "\n",
    "model.fit(X,y,epochs=100)\n",
    "# 데이터 x와 레이블 y로 100번의 에포크, 즉 반복 동안 학습시킨다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 유형에 따른 활성화 함수의 선택\n",
    "\n",
    ">이진 분류\n",
    "\n",
    "출력 레이어에 보통 sigmoid 함수를 사용합니다\n",
    "\n",
    "이 함수는 출력값을 0과 1 사이로 압축해 주며, 이 값은 클래스 1의 확률로 해석됩니다\n",
    "\n",
    ">다중 클래스 분류\n",
    "\n",
    "출력 레이어에 softmax 함수를 사용합니다\n",
    "\n",
    "이 함수는 여러 개의 클래스로 나뉜 확률 분포를 생성합니다\n",
    "\n",
    ">회귀 문제\n",
    "\n",
    "출력 레이어에 활성화 함수를 사용하지 않거나(즉, 선형 활성화) ReLU 같은 함수를 사용합니다\n",
    "\n",
    "이 경우 출력값은 실수 값으로 나타납니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_1 (Dense)             (None, 12)                108       \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 8)                 104       \n",
      "                                                                 \n",
      " Dense_3 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 221 (884.00 Byte)\n",
      "Trainable params: 221 (884.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "154/154 [==============================] - 1s 1ms/step - loss: 1.8577 - accuracy: 0.4753\n",
      "Epoch 2/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 1.0873 - accuracy: 0.5052\n",
      "Epoch 3/100\n",
      "154/154 [==============================] - 0s 944us/step - loss: 0.9443 - accuracy: 0.5521\n",
      "Epoch 4/100\n",
      "154/154 [==============================] - 0s 920us/step - loss: 0.8174 - accuracy: 0.6081\n",
      "Epoch 5/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.7529 - accuracy: 0.6380\n",
      "Epoch 6/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.7342 - accuracy: 0.6315\n",
      "Epoch 7/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.6761 - accuracy: 0.6562\n",
      "Epoch 8/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.6540 - accuracy: 0.6576\n",
      "Epoch 9/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.6355 - accuracy: 0.6940\n",
      "Epoch 10/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.6433 - accuracy: 0.6745\n",
      "Epoch 11/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.6539 - accuracy: 0.6719\n",
      "Epoch 12/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.6149 - accuracy: 0.6732\n",
      "Epoch 13/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.6144 - accuracy: 0.6875\n",
      "Epoch 14/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.6100 - accuracy: 0.7109\n",
      "Epoch 15/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.6055 - accuracy: 0.7005\n",
      "Epoch 16/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.6233 - accuracy: 0.6797\n",
      "Epoch 17/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.6293 - accuracy: 0.6797\n",
      "Epoch 18/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.6052 - accuracy: 0.6979\n",
      "Epoch 19/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5838 - accuracy: 0.7253\n",
      "Epoch 20/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.6144 - accuracy: 0.6875\n",
      "Epoch 21/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5996 - accuracy: 0.6901\n",
      "Epoch 22/100\n",
      "154/154 [==============================] - 0s 946us/step - loss: 0.5972 - accuracy: 0.6888\n",
      "Epoch 23/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5835 - accuracy: 0.7148\n",
      "Epoch 24/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.7083\n",
      "Epoch 25/100\n",
      "154/154 [==============================] - 0s 966us/step - loss: 0.6123 - accuracy: 0.6888\n",
      "Epoch 26/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5799 - accuracy: 0.6979\n",
      "Epoch 27/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5759 - accuracy: 0.7031\n",
      "Epoch 28/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5807 - accuracy: 0.6940\n",
      "Epoch 29/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5943 - accuracy: 0.7005\n",
      "Epoch 30/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5698 - accuracy: 0.7005\n",
      "Epoch 31/100\n",
      "154/154 [==============================] - 0s 953us/step - loss: 0.5920 - accuracy: 0.7122\n",
      "Epoch 32/100\n",
      "154/154 [==============================] - 0s 938us/step - loss: 0.5962 - accuracy: 0.7135\n",
      "Epoch 33/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5631 - accuracy: 0.7188\n",
      "Epoch 34/100\n",
      "154/154 [==============================] - 0s 969us/step - loss: 0.5616 - accuracy: 0.7083\n",
      "Epoch 35/100\n",
      "154/154 [==============================] - 0s 940us/step - loss: 0.5696 - accuracy: 0.7188\n",
      "Epoch 36/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5677 - accuracy: 0.7122\n",
      "Epoch 37/100\n",
      "154/154 [==============================] - 0s 935us/step - loss: 0.5653 - accuracy: 0.7161\n",
      "Epoch 38/100\n",
      "154/154 [==============================] - 0s 934us/step - loss: 0.5730 - accuracy: 0.7174\n",
      "Epoch 39/100\n",
      "154/154 [==============================] - 0s 933us/step - loss: 0.5837 - accuracy: 0.6940\n",
      "Epoch 40/100\n",
      "154/154 [==============================] - 0s 950us/step - loss: 0.5587 - accuracy: 0.7240\n",
      "Epoch 41/100\n",
      "154/154 [==============================] - 0s 927us/step - loss: 0.5604 - accuracy: 0.7240\n",
      "Epoch 42/100\n",
      "154/154 [==============================] - 0s 934us/step - loss: 0.5788 - accuracy: 0.7044\n",
      "Epoch 43/100\n",
      "154/154 [==============================] - 0s 944us/step - loss: 0.5589 - accuracy: 0.7188\n",
      "Epoch 44/100\n",
      "154/154 [==============================] - 0s 937us/step - loss: 0.5669 - accuracy: 0.7135\n",
      "Epoch 45/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5658 - accuracy: 0.7253\n",
      "Epoch 46/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5511 - accuracy: 0.7279\n",
      "Epoch 47/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5536 - accuracy: 0.7240\n",
      "Epoch 48/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5505 - accuracy: 0.7240\n",
      "Epoch 49/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5437 - accuracy: 0.7214\n",
      "Epoch 50/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5463 - accuracy: 0.7227\n",
      "Epoch 51/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5819 - accuracy: 0.7018\n",
      "Epoch 52/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.7409\n",
      "Epoch 53/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.7279\n",
      "Epoch 54/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.5545 - accuracy: 0.7227\n",
      "Epoch 55/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5478 - accuracy: 0.7344\n",
      "Epoch 56/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5430 - accuracy: 0.7253\n",
      "Epoch 57/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5447 - accuracy: 0.7409\n",
      "Epoch 58/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5424 - accuracy: 0.7266\n",
      "Epoch 59/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7344\n",
      "Epoch 60/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5388 - accuracy: 0.7279\n",
      "Epoch 61/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5453 - accuracy: 0.7318\n",
      "Epoch 62/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7266\n",
      "Epoch 63/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5349 - accuracy: 0.7305\n",
      "Epoch 64/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5369 - accuracy: 0.7396\n",
      "Epoch 65/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5329 - accuracy: 0.7357\n",
      "Epoch 66/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5291 - accuracy: 0.7422\n",
      "Epoch 67/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5346 - accuracy: 0.7344\n",
      "Epoch 68/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5373 - accuracy: 0.7357\n",
      "Epoch 69/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5270 - accuracy: 0.7435\n",
      "Epoch 70/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5341 - accuracy: 0.7279\n",
      "Epoch 71/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5237 - accuracy: 0.7487\n",
      "Epoch 72/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.7266\n",
      "Epoch 73/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5352 - accuracy: 0.7409\n",
      "Epoch 74/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5369 - accuracy: 0.7448\n",
      "Epoch 75/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5317 - accuracy: 0.7422\n",
      "Epoch 76/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5361 - accuracy: 0.7448\n",
      "Epoch 77/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5224 - accuracy: 0.7422\n",
      "Epoch 78/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5373 - accuracy: 0.7409\n",
      "Epoch 79/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5215 - accuracy: 0.7448\n",
      "Epoch 80/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5288 - accuracy: 0.7487\n",
      "Epoch 81/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5605 - accuracy: 0.7109\n",
      "Epoch 82/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5204 - accuracy: 0.7318\n",
      "Epoch 83/100\n",
      "154/154 [==============================] - 0s 967us/step - loss: 0.5193 - accuracy: 0.7253\n",
      "Epoch 84/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5195 - accuracy: 0.7448\n",
      "Epoch 85/100\n",
      "154/154 [==============================] - 0s 954us/step - loss: 0.5437 - accuracy: 0.7214\n",
      "Epoch 86/100\n",
      "154/154 [==============================] - 0s 968us/step - loss: 0.5275 - accuracy: 0.7370\n",
      "Epoch 87/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5343 - accuracy: 0.7279\n",
      "Epoch 88/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5217 - accuracy: 0.7344\n",
      "Epoch 89/100\n",
      "154/154 [==============================] - 0s 978us/step - loss: 0.5421 - accuracy: 0.7331\n",
      "Epoch 90/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5267 - accuracy: 0.7318\n",
      "Epoch 91/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5312 - accuracy: 0.7435\n",
      "Epoch 92/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5207 - accuracy: 0.7396\n",
      "Epoch 93/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5188 - accuracy: 0.7396\n",
      "Epoch 94/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5086 - accuracy: 0.7513\n",
      "Epoch 95/100\n",
      "154/154 [==============================] - 0s 959us/step - loss: 0.5135 - accuracy: 0.7487\n",
      "Epoch 96/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5145 - accuracy: 0.7604\n",
      "Epoch 97/100\n",
      "154/154 [==============================] - 0s 944us/step - loss: 0.5250 - accuracy: 0.7409\n",
      "Epoch 98/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5324 - accuracy: 0.7214\n",
      "Epoch 99/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5227 - accuracy: 0.7409\n",
      "Epoch 100/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.5245 - accuracy: 0.7357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1de8fd882e0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2=Sequential()\n",
    "model2.add(Dense(12,input_dim=8,activation='relu'))\n",
    "model2.add(Dense(8,activation='relu'))\n",
    "model2.add(Dense(1,activation='sigmoid'))\n",
    "model2.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',metrics=['accuracy'])\n",
    "model2.fit(X,y,epochs=100,batch_size=5)\n",
    "# 모델이 파라미터를 업데이트하기 위해 사용하는 데이터의 샘플의 수\n",
    "# 데이터를 작은 배치로 나누어 처리한다\n",
    "# 각 배치에서 모델의 가중치를 업데이트한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                108       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 221 (884.00 Byte)\n",
      "Trainable params: 221 (884.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()\n",
    "# 레이어들의 매개변수\n",
    "\n",
    "# 예) 첫 번째 레이어\n",
    "# 입력*출력=8*12=96\n",
    "# 출력 차원 12개\n",
    "# 96+12=108\n",
    "\n",
    "# 전체 매개변수\n",
    "# 학습 가능한 것과 학습 불가능한 것을 합친 것\n",
    "\n",
    "# 학습 가능한 매개변수\n",
    "# 학습 과정에서 모델이 업데이트하는 매개변수"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldltest1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
